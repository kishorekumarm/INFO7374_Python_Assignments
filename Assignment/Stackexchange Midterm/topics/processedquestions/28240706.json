{"owner": {"display_name": "ab_tech_sp", "reputation": 83, "profile_image": "https://www.gravatar.com/avatar/309cce0eb864ddf3e74d4d568f591328?s=128&d=identicon&r=PG&f=1", "user_id": 4512281, "user_type": "registered", "link": "http://stackoverflow.com/users/4512281/ab-tech-sp"}, "link": "http://stackoverflow.com/questions/28240706/explain-the-aggregate-functionality-in-spark", "tags": ["python", "apache-spark", "lambda", "aggregate", "rdd"], "creation_date": 1422636558, "score": 16, "last_edit_date": 1471620234, "is_answered": true, "view_count": 8361, "last_activity_date": 1477366746, "question_id": 28240706, "accepted_answer_id": 28241948, "answer_count": 4, "title": "Explain the aggregate functionality in Spark"}