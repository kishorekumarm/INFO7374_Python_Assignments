{"owner": {"display_name": "MartyMacGyver", "reputation": 1965, "profile_image": "https://i.stack.imgur.com/Ih6PP.jpg?s=128&g=1", "user_id": 760905, "user_type": "registered", "accept_rate": 89, "link": "http://stackoverflow.com/users/760905/martymacgyver"}, "link": "http://stackoverflow.com/questions/40325437/how-to-efficiently-fan-out-large-chunks-of-data-into-multiple-concurrent-sub-pro", "tags": ["python", "multiprocessing", "shared-memory", "python-multiprocessing"], "creation_date": 1477793047, "score": 0, "last_edit_date": 1477804490, "is_answered": false, "view_count": 39, "last_activity_date": 1477804490, "question_id": 40325437, "answer_count": 0, "title": "How to efficiently fan out large chunks of data into multiple concurrent sub-processes in Python?"}