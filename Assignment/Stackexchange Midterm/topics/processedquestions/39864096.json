{"owner": {"display_name": "johnnyb", "reputation": 20, "profile_image": "https://lh6.googleusercontent.com/-HaaAI166T-8/AAAAAAAAAAI/AAAAAAAALjI/GJMj2s8Y100/photo.jpg?sz=128", "user_id": 6916973, "user_type": "registered", "link": "http://stackoverflow.com/users/6916973/johnnyb"}, "link": "http://stackoverflow.com/questions/39864096/what-is-the-most-efficient-way-to-compare-45-million-rows-of-text-file-to-about", "tags": ["python", "pandas", "iteration", "large-files"], "creation_date": 1475630795, "score": 3, "last_edit_date": 1475639334, "is_answered": true, "view_count": 64, "last_activity_date": 1477357554, "question_id": 39864096, "accepted_answer_id": 40229838, "answer_count": 3, "title": "What is the most efficient way to compare 45 Million rows of Text File to about 200k rows text file and produce non matches from the smaller file?"}