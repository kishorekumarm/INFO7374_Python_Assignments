{"is_answered": true, "view_count": 1040, "tags": ["python", "pandas", "nltk"], "last_activity_date": 1468271045, "answer_count": 2, "creation_date": 1444725895, "score": -1, "link": "http://stackoverflow.com/questions/33098040/how-to-use-word-tokenize-in-data-frame", "accepted_answer_id": 33098350, "owner": {"user_id": 5325665, "profile_image": "https://www.gravatar.com/avatar/b2cb96908cd8369ba9267e9ecd9dc719?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 102, "link": "http://stackoverflow.com/users/5325665/eclairs", "accept_rate": 63, "display_name": "eclairs"}, "title": "how to use word_tokenize in data frame", "last_edit_date": 1444727555, "question_id": 33098040}